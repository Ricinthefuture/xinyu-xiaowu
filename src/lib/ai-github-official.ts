// åŸºäºGitHubå®˜æ–¹æ–‡æ¡£çš„GitHub Models APIå®¢æˆ·ç«¯
// å‚è€ƒ: https://github.blog/ai-and-ml/llms/solving-the-inference-problem-for-open-source-ai-projects-with-github-models/

interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

interface EmotionAnalysis {
  event: string
  belief: string
  emotion: string
  intensity: number
}

class GitHubModelsOfficialClient {
  private apiToken: string
  private chatEndpoint = 'https://models.github.ai/inference/chat/completions' // å®˜æ–¹ç«¯ç‚¹
  private defaultModel = 'gpt-4o-mini' // é»˜è®¤æ¨¡å‹

  constructor() {
    this.apiToken = process.env.GITHUB_TOKEN || ''
    console.log('ğŸ”§ GitHub Modelså®˜æ–¹å®¢æˆ·ç«¯åˆå§‹åŒ–')
    console.log('ğŸ”‘ TokençŠ¶æ€:', {
      hasToken: !!this.apiToken,
      tokenLength: this.apiToken?.length || 0,
      tokenPrefix: this.apiToken?.substring(0, 20) + '...'
    })
  }

  async processUserMessage(userMessage: string, conversationHistory: ChatMessage[] = []): Promise<string> {
    console.log('ğŸš€ å¼€å§‹GitHub Models APIè°ƒç”¨ï¼ˆå®˜æ–¹æ–¹å¼ï¼‰...')
    
    const messages: ChatMessage[] = [
      { role: 'system', content: this.getSystemPrompt() },
      ...conversationHistory.slice(-6),
      { role: 'user', content: userMessage }
    ]

    console.log('ğŸ“ å‘é€çš„æ¶ˆæ¯:', {
      model: this.defaultModel,
      messagesCount: messages.length,
      endpoint: this.chatEndpoint
    })

    try {
      // åˆ›å»ºå¸¦è¶…æ—¶çš„fetchè¯·æ±‚
      const controller = new AbortController()
      const timeoutId = setTimeout(() => controller.abort(), 30000) // 30ç§’è¶…æ—¶

      const response = await fetch(this.chatEndpoint, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiToken}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({
          model: this.defaultModel,
          messages: messages,
          max_tokens: 1000,
          temperature: 0.7
        }),
        signal: controller.signal
      })

      clearTimeout(timeoutId)

      console.log('ğŸ“Š APIå“åº”çŠ¶æ€:', response.status)
      console.log('ğŸ“‹ å“åº”å¤´:', Object.fromEntries(response.headers.entries()))

      if (!response.ok) {
        const errorText = await response.text()
        console.error('âŒ APIè¯·æ±‚å¤±è´¥:', {
          status: response.status,
          statusText: response.statusText,
          body: errorText
        })
        throw new Error(`GitHub Models APIé”™è¯¯: ${response.status} ${response.statusText}`)
      }

      const data = await response.json()
      console.log('ğŸ“„ APIå“åº”æ•°æ®:', data)

      if (data.choices && data.choices[0] && data.choices[0].message) {
        const aiResponse = data.choices[0].message.content
        console.log('âœ… GitHub Models APIè°ƒç”¨æˆåŠŸ!')
        console.log('ğŸ“„ AIå›å¤é¢„è§ˆ:', aiResponse.substring(0, 100) + '...')
        return aiResponse
      } else {
        console.error('âŒ å“åº”æ ¼å¼å¼‚å¸¸:', data)
        throw new Error('GitHub Models APIè¿”å›æ ¼å¼å¼‚å¸¸')
      }

    } catch (error) {
      console.error('ğŸ”¥ GitHub Models APIè°ƒç”¨å¤±è´¥:', error)
      console.warn('âš ï¸ å›é€€åˆ°æ™ºèƒ½å›å¤ç³»ç»Ÿ')
      return this.generateIntelligentResponse(userMessage, conversationHistory)
    }
  }

  async analyzeEmotion(userMessage: string): Promise<EmotionAnalysis> {
    console.log('ğŸ§  å¼€å§‹æƒ…ç»ªåˆ†æï¼ˆå®˜æ–¹APIï¼‰...')
    
    const messages: ChatMessage[] = [
      { 
        role: 'system', 
        content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…ç»ªåˆ†æå¸ˆï¼ŒåŸºäºABCç†è®ºåˆ†æç”¨æˆ·çš„æƒ…ç»ªã€‚è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«eventã€beliefã€emotionã€intensityå­—æ®µã€‚'
      },
      { 
        role: 'user', 
        content: `è¯·åˆ†æè¿™æ®µè¯çš„æƒ…ç»ªï¼š${userMessage}` 
      }
    ]

    try {
      const response = await fetch(this.chatEndpoint, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiToken}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({
          model: this.defaultModel,
          messages: messages,
          max_tokens: 200,
          temperature: 0.3
        })
      })

      if (response.ok) {
        const data = await response.json()
        const analysisText = data.choices[0].message.content
        
        try {
          const analysis = JSON.parse(analysisText)
          console.log('âœ… æƒ…ç»ªåˆ†ææˆåŠŸ:', analysis)
          return analysis
        } catch (parseError) {
          console.warn('âš ï¸ æƒ…ç»ªåˆ†æJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ')
        }
      }
    } catch (error) {
      console.error('âŒ æƒ…ç»ªåˆ†æAPIè°ƒç”¨å¤±è´¥:', error)
    }

    // å›é€€åˆ°ç®€å•åˆ†æ
    return this.getBasicEmotionAnalysis(userMessage)
  }

  private getSystemPrompt(): string {
    return `ä½ æ˜¯å¿ƒè¯­å°å±‹çš„AIæƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ï¼Œä¸“é—¨è¿ç”¨ABCç†è®ºå¸®åŠ©ç”¨æˆ·ç®¡ç†æƒ…ç»ªã€‚

ABCç†è®ºæ ¸å¿ƒï¼š
- A (Activating Event): è§¦å‘äº‹ä»¶
- B (Belief): ä¸ªäººä¿¡å¿µå’Œæƒ³æ³•
- C (Consequence): æƒ…ç»ªå’Œè¡Œä¸ºç»“æœ

è¯·ä»¥æ¸©æš–ã€ä¸“ä¸šçš„æ–¹å¼å›åº”ç”¨æˆ·ï¼Œå¸®åŠ©ä»–ä»¬ï¼š
1. è¯†åˆ«è§¦å‘äº‹ä»¶(A)
2. æ¢ç´¢å†…åœ¨ä¿¡å¿µ(B)
3. ç†è§£æƒ…ç»ªååº”(C)
4. æä¾›ç§¯æçš„åº”å¯¹å»ºè®®

ä¿æŒå›å¤ç®€æ´(150å­—å†…)ã€æ¸©æš–ä¸”å¯Œæœ‰åŒç†å¿ƒã€‚ä½¿ç”¨é€‚å½“çš„emojiå¢åŠ äº²åˆ‡æ„Ÿã€‚`
  }

  private generateIntelligentResponse(userMessage: string, conversationHistory: ChatMessage[] = []): string {
    const lowerMessage = userMessage.toLowerCase()
    
    // åŸºäºABCç†è®ºçš„å›å¤æ¨¡æ¿
    if (lowerMessage.includes('ç„¦è™‘') || lowerMessage.includes('æ‹…å¿ƒ') || lowerMessage.includes('ç´§å¼ ')) {
      return `æˆ‘èƒ½æ„Ÿå—åˆ°æ‚¨ç°åœ¨çš„ç„¦è™‘æƒ…ç»ª ğŸŒ¸ è®©æˆ‘ä»¬ä¸€èµ·ç”¨ABCç†è®ºæ¥çœ‹çœ‹è¿™ä¸ªæƒ…å†µï¼š

**A (äº‹ä»¶)**: ä»€ä¹ˆäº‹æƒ…è®©æ‚¨æ„Ÿåˆ°ç„¦è™‘ï¼Ÿ
**B (ä¿¡å¿µ)**: æ‚¨å¯¹è¿™ä»¶äº‹æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Ÿæ˜¯å¦æ‹…å¿ƒä¼šå‘ç”Ÿä¸å¥½çš„ç»“æœï¼Ÿ
**C (æƒ…ç»ª)**: è¿™äº›æƒ³æ³•å¸¦æ¥äº†ç„¦è™‘çš„æ„Ÿå—ã€‚

è®°ä½ï¼Œæˆ‘ä»¬æ— æ³•æ§åˆ¶äº‹ä»¶ï¼Œä½†å¯ä»¥è°ƒæ•´æˆ‘ä»¬çš„æƒ³æ³•ã€‚æ‚¨æ„¿æ„å’Œæˆ‘åˆ†äº«æ›´å¤šç»†èŠ‚å—ï¼ŸğŸ’•`
    }

    if (lowerMessage.includes('éš¾è¿‡') || lowerMessage.includes('ä¼¤å¿ƒ') || lowerMessage.includes('æ‚²ä¼¤')) {
      return `æˆ‘å¬åˆ°äº†æ‚¨å†…å¿ƒçš„å£°éŸ³ï¼Œæ„Ÿå—åˆ°æ‚¨çš„éš¾è¿‡ ğŸ’• æ‚²ä¼¤æ˜¯ä¸€ç§å¾ˆè‡ªç„¶çš„æƒ…ç»ªï¼Œè®©æˆ‘ä»¬ç”¨ABCç†è®ºæ¥ç†è§£ï¼š

**A (äº‹ä»¶)**: ä»€ä¹ˆäº‹æƒ…è®©æ‚¨æ„Ÿåˆ°éš¾è¿‡ï¼Ÿ
**B (ä¿¡å¿µ)**: æ‚¨å¯¹è¿™ä»¶äº‹æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Ÿæ˜¯å¦è§‰å¾—å¤±å»äº†ä»€ä¹ˆé‡è¦çš„ä¸œè¥¿ï¼Ÿ
**C (æƒ…ç»ª)**: è¿™äº›æƒ³æ³•å¸¦æ¥äº†æ‚²ä¼¤çš„æ„Ÿå—ã€‚

æ‚²ä¼¤æœ‰æ—¶æ˜¯æˆ‘ä»¬å†…å¿ƒåœ¨å¤„ç†å¤±å»å’Œå˜åŒ–çš„æ–¹å¼ã€‚æ‚¨æ„¿æ„å’Œæˆ‘åˆ†äº«æ›´å¤šå—ï¼Ÿâœ¨`
    }

    if (lowerMessage.includes('æ„¤æ€’') || lowerMessage.includes('ç”Ÿæ°”') || lowerMessage.includes('æ°”æ„¤')) {
      return `æˆ‘ç†è§£æ‚¨ç°åœ¨çš„æ„¤æ€’æƒ…ç»ª ğŸŒ¿ æ„¤æ€’å¾€å¾€æ˜¯å…¶ä»–æƒ…ç»ªçš„è¡¨è¾¾ï¼Œè®©æˆ‘ä»¬ç”¨ABCç†è®ºæ¥æ¢ç´¢ï¼š

**A (äº‹ä»¶)**: ä»€ä¹ˆäº‹æƒ…è§¦å‘äº†æ‚¨çš„æ„¤æ€’ï¼Ÿ
**B (ä¿¡å¿µ)**: æ‚¨è§‰å¾—è¿™ä»¶äº‹æ˜¯ä¸å…¬å¹³çš„å—ï¼Ÿæˆ–è€…è¿èƒŒäº†æ‚¨çš„ä»·å€¼è§‚ï¼Ÿ
**C (æƒ…ç»ª)**: è¿™äº›æƒ³æ³•æ¿€å‘äº†æ„¤æ€’çš„æƒ…ç»ªã€‚

æ„¤æ€’æœ‰æ—¶æ˜¯åœ¨ä¿æŠ¤æˆ‘ä»¬è®¤ä¸ºé‡è¦çš„ä¸œè¥¿ã€‚æ‚¨èƒ½å‘Šè¯‰æˆ‘æ›´å¤šèƒŒæ™¯å—ï¼ŸğŸŒ±`
    }

    // é»˜è®¤å›å¤
    return `æˆ‘èƒ½æ„Ÿå—åˆ°æ‚¨æƒ³è¦è¡¨è¾¾çš„æƒ…æ„Ÿ ğŸŒ¸ è™½ç„¶æ¯ä¸ªäººçš„ç»å†éƒ½ä¸åŒï¼Œä½†æƒ…ç»ªçš„æ„Ÿå—æ˜¯ç›¸é€šçš„ã€‚

è®©æˆ‘ä»¬ç”¨ABCç†è®ºæ¥çœ‹çœ‹æ‚¨çš„æƒ…å†µï¼š
- **A (äº‹ä»¶)**: å‘ç”Ÿäº†ä»€ä¹ˆè®©æ‚¨æœ‰è¿™æ ·çš„æ„Ÿå—ï¼Ÿ
- **B (ä¿¡å¿µ)**: æ‚¨å¯¹è¿™ä»¶äº‹æœ‰ä»€ä¹ˆæƒ³æ³•ï¼Ÿ
- **C (æƒ…ç»ª)**: è¿™äº›æƒ³æ³•å¦‚ä½•å½±å“äº†æ‚¨çš„æƒ…ç»ªï¼Ÿ

æˆ‘ä¼šé™ªä¼´æ‚¨ä¸€èµ·æ¢ç´¢å’Œç†è§£ã€‚è¯·å’Œæˆ‘åˆ†äº«æ›´å¤šå§ ğŸ’•`
  }

  private getBasicEmotionAnalysis(userMessage: string): EmotionAnalysis {
    const lowerMessage = userMessage.toLowerCase()
    
    if (lowerMessage.includes('ç„¦è™‘') || lowerMessage.includes('æ‹…å¿ƒ')) {
      return {
        event: userMessage,
        belief: "å¯èƒ½å­˜åœ¨å¯¹æœªæ¥ä¸ç¡®å®šæ€§çš„æ‹…å¿§",
        emotion: "ç„¦è™‘",
        intensity: 6
      }
    }
    
    if (lowerMessage.includes('éš¾è¿‡') || lowerMessage.includes('ä¼¤å¿ƒ')) {
      return {
        event: userMessage,
        belief: "å¯èƒ½ç»å†äº†å¤±å»æˆ–æŒ«æŠ˜",
        emotion: "æ‚²ä¼¤",
        intensity: 5
      }
    }
    
    if (lowerMessage.includes('æ„¤æ€’') || lowerMessage.includes('ç”Ÿæ°”')) {
      return {
        event: userMessage,
        belief: "å¯èƒ½æ„Ÿåˆ°ä¸å…¬å¹³æˆ–è¢«ä¾µçŠ¯",
        emotion: "æ„¤æ€’",
        intensity: 7
      }
    }
    
    return {
      event: userMessage,
      belief: "å¯èƒ½å­˜åœ¨ä¸€äº›éœ€è¦è¿›ä¸€æ­¥æ¢ç´¢çš„å†…åœ¨ä¿¡å¿µæ¨¡å¼",
      emotion: "æ··åˆæƒ…ç»ª",
      intensity: 5
    }
  }

  // æ£€æŸ¥æƒé™çš„æ–¹æ³•
  async checkPermissions(): Promise<{ hasAccess: boolean, error?: string }> {
    try {
      console.log('ğŸ” æ£€æŸ¥GitHub Modelsæƒé™...')
      
      const testResponse = await fetch(this.chatEndpoint, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiToken}`,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({
          model: this.defaultModel,
          messages: [{ role: 'user', content: 'test' }],
          max_tokens: 1
        })
      })

      console.log('ğŸ“Š æƒé™æ£€æŸ¥å“åº”:', testResponse.status)

      if (testResponse.ok || testResponse.status === 400) {
        return { hasAccess: true }
      } else if (testResponse.status === 401 || testResponse.status === 403) {
        const errorData = await testResponse.json().catch(() => ({ error: { message: 'Permission denied' } }))
        return {
          hasAccess: false,
          error: errorData.error?.message || `éœ€è¦models:readæƒé™`
        }
      } else {
        return {
          hasAccess: false,
          error: `HTTP ${testResponse.status}`
        }
      }
    } catch (error) {
      return {
        hasAccess: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      }
    }
  }
}

export const githubModelsOfficialAI = new GitHubModelsOfficialClient()

export function handleAIError(error: unknown): string {
  console.error('ğŸ”¥ GitHub Models AIé”™è¯¯:', error)

  if (error instanceof Error) {
    if (error.message.includes('æƒé™ä¸è¶³') || error.message.includes('models:read')) {
      return `GitHub Tokenéœ€è¦models:readæƒé™ã€‚è¯·ç¡®ä¿æ‚¨çš„Personal Access Tokenå…·æœ‰"models:read"æƒé™ã€‚è¯¦æƒ…è¯·å‚è€ƒï¼šhttps://github.blog/ai-and-ml/llms/solving-the-inference-problem-for-open-source-ai-projects-with-github-models/`
    }
    if (error.message.includes('è®¤è¯å¤±è´¥')) {
      return `GitHub Tokenè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥Tokenæ˜¯å¦æœ‰æ•ˆä¸”å…·æœ‰models:readæƒé™ã€‚`
    }
  }

  return 'æŠ±æ­‰ï¼ŒGitHub Models APIæš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åå†è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚'
}
