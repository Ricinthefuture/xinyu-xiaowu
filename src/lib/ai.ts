// GitHub Models API å®¢æˆ·ç«¯
// ä½¿ç”¨ GitHub Models æ›¿ä»£ OpenAI

interface GitHubModelsResponse {
  choices: Array<{
    message: {
      role: string
      content: string
    }
    finish_reason: string
  }>
  usage?: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

class GitHubModelsClient {
  private apiToken: string
  private baseUrl = 'https://models.inference.ai.azure.com'
  private model = 'gpt-4o-mini' // æˆ–å…¶ä»–å¯ç”¨æ¨¡å‹

  constructor() {
    this.apiToken = process.env.GITHUB_TOKEN || ''
    if (!this.apiToken) {
      throw new Error('GITHUB_TOKEN is required for AI functionality')
    }
  }

  async chat(messages: ChatMessage[]): Promise<string> {
    try {
      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiToken}`,
        },
        body: JSON.stringify({
          model: this.model,
          messages,
          max_tokens: 1000,
          temperature: 0.7,
          stream: false
        })
      })

      if (!response.ok) {
        throw new Error(`GitHub Models API error: ${response.status} ${response.statusText}`)
      }

      const data: GitHubModelsResponse = await response.json()
      
      if (!data.choices || data.choices.length === 0) {
        throw new Error('No response from AI model')
      }

      return data.choices[0].message.content
    } catch (error) {
      console.error('GitHub Models API error:', error)
      throw new Error('AI service is currently unavailable')
    }
  }

  async streamChat(messages: ChatMessage[]): Promise<ReadableStream> {
    const response = await fetch(`${this.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiToken}`,
      },
      body: JSON.stringify({
        model: this.model,
        messages,
        max_tokens: 1000,
        temperature: 0.7,
        stream: true
      })
    })

    if (!response.ok) {
      throw new Error(`GitHub Models API error: ${response.status}`)
    }

    return response.body!
  }
}

// ABC ç†è®ºç›¸å…³çš„ AI åŠ©æ‰‹
export class EmotionAIAssistant {
  private client: GitHubModelsClient

  constructor() {
    this.client = new GitHubModelsClient()
  }

  // ç³»ç»Ÿæç¤ºè¯ - ABCç†è®ºæŒ‡å¯¼
  private getSystemPrompt(): string {
    return `ä½ æ˜¯"å¿ƒè¯­å°å±‹"çš„AIæƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ï¼Œä¸“é—¨è¿ç”¨ABCç†è®ºå¸®åŠ©ç”¨æˆ·ç®¡ç†æƒ…ç»ªã€‚

ABCç†è®ºè¯´æ˜ï¼š
- A (Activating Event): æ¿€å‘äº‹ä»¶
- B (Belief): ä¿¡å¿µ/æƒ³æ³•
- C (Consequence): æƒ…ç»ªå’Œè¡Œä¸ºç»“æœ

ä½ çš„ä»»åŠ¡ï¼š
1. æ¸©å’Œåœ°å€¾å¬ç”¨æˆ·çš„å›°æ‰°
2. å¸®åŠ©ç”¨æˆ·è¯†åˆ«è§¦å‘äº‹ä»¶(A)
3. æ¢ç´¢ç”¨æˆ·çš„å†…åœ¨ä¿¡å¿µ(B)
4. åˆ†ææƒ…ç»ªååº”(C)
5. å¼•å¯¼ç”¨æˆ·é‡æ–°å®¡è§†å’Œè°ƒæ•´ä¸åˆç†ä¿¡å¿µ
6. æä¾›æ¸©æš–çš„æ”¯æŒå’Œå®ç”¨çš„å»ºè®®

å›å¤é£æ ¼ï¼š
- æ¸©æš–ã€åŒç†å¿ƒã€éè¯„åˆ¤æ€§
- ä½¿ç”¨æ¸©å’Œçš„é—®å¥å¼•å¯¼æ€è€ƒ
- é¿å…è¯´æ•™ï¼Œå¤šç”¨å€¾å¬å’Œç†è§£
- é€‚å½“ä½¿ç”¨æ¸©æš–çš„è¡¨æƒ…ç¬¦å· ğŸŒ¸ğŸ’•âœ¨
- è¯­è¨€ç®€æ´æ˜“æ‡‚ï¼Œå……æ»¡å…³æ€€

è®°ä½ï¼šä½ æ˜¯ä¸€ä¸ªæ¸©æš–çš„é™ªä¼´è€…ï¼Œä¸æ˜¯å†·å†°å†°çš„æœºå™¨äººã€‚`
  }

  async processUserMessage(userMessage: string, conversationHistory: ChatMessage[] = []): Promise<string> {
    const messages: ChatMessage[] = [
      { role: 'system', content: this.getSystemPrompt() },
      ...conversationHistory,
      { role: 'user', content: userMessage }
    ]

    return await this.client.chat(messages)
  }

  async analyzeEmotion(userInput: string): Promise<{
    event: string
    belief: string
    emotion: string
    intensity: number
  }> {
    const analysisPrompt = `è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥ï¼ŒæŒ‰ABCç†è®ºè¯†åˆ«ï¼š

ç”¨æˆ·è¾“å…¥ï¼š"${userInput}"

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
  "event": "å…·ä½“å‘ç”Ÿçš„äº‹ä»¶(A)",
  "belief": "ç”¨æˆ·çš„å†…åœ¨ä¿¡å¿µæˆ–æƒ³æ³•(B)", 
  "emotion": "äº§ç”Ÿçš„æƒ…ç»ª(C)",
  "intensity": 1-10çš„æƒ…ç»ªå¼ºåº¦æ•°å€¼
}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚`

    try {
      const response = await this.client.chat([
        { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæƒ…ç»ªåˆ†æä¸“å®¶ï¼Œä¸“é—¨è¿ç”¨ABCç†è®ºåˆ†æç”¨æˆ·æƒ…ç»ªã€‚' },
        { role: 'user', content: analysisPrompt }
      ])

      return JSON.parse(response)
    } catch (error) {
      console.error('Emotion analysis failed:', error)
      // è¿”å›é»˜è®¤å€¼
      return {
        event: userInput,
        belief: 'æœªè¯†åˆ«',
        emotion: 'æ··åˆæƒ…ç»ª',
        intensity: 5
      }
    }
  }

  async streamResponse(userMessage: string, conversationHistory: ChatMessage[] = []): Promise<ReadableStream> {
    const messages: ChatMessage[] = [
      { role: 'system', content: this.getSystemPrompt() },
      ...conversationHistory,
      { role: 'user', content: userMessage }
    ]

    return await this.client.streamChat(messages)
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const emotionAI = new EmotionAIAssistant()

// é”™è¯¯å¤„ç†åŠ©æ‰‹
export function handleAIError(error: unknown): string {
  console.error('AI Error:', error)
  
  if (error instanceof Error) {
    if (error.message.includes('API error')) {
      return 'æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»å®¢æœã€‚ğŸ’•'
    }
    if (error.message.includes('token')) {
      return 'æŠ±æ­‰ï¼ŒæœåŠ¡é…ç½®æœ‰è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚ğŸŒ¸'
    }
  }
  
  return 'æŠ±æ­‰ï¼Œå‡ºç°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è®©æˆ‘ä»¬ç¨åå†ç»§ç»­å¯¹è¯å§ã€‚âœ¨'
}
