import { NextRequest, NextResponse } from 'next/server'

export async function GET() {
  const githubToken = process.env.GITHUB_TOKEN

  if (!githubToken) {
    return NextResponse.json({ 
      error: 'GITHUB_TOKEN missing',
      solution: 'è¯·åœ¨.env.localä¸­è®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡'
    }, { status: 400 })
  }

  try {
    console.log('ğŸ§ª æµ‹è¯•ä¿®å¤åçš„GitHub Models API...')
    
    const requestBody = {
      model: 'openai/gpt-4o-mini', // ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°æ ¼å¼
      messages: [
        { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚è¯·ç®€çŸ­å›å¤ã€‚' },
        { role: 'user', content: 'ä½ å¥½' }
      ],
      max_tokens: 50,
      temperature: 0.7
    }

    console.log('ğŸ“¤ å‘é€è¯·æ±‚åˆ°æ­£ç¡®çš„ç«¯ç‚¹:', 'https://models.github.ai/inference/chat/completions')
    console.log('ğŸ”‘ Tokenå‰ç¼€:', githubToken.substring(0, 20) + '...')
    console.log('ğŸ“ ä½¿ç”¨æ¨¡å‹:', requestBody.model)

    const response = await fetch('https://models.github.ai/inference/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${githubToken}`,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        'User-Agent': 'EmotionAI-HeartHouse/1.0'
      },
      body: JSON.stringify(requestBody)
    })

    console.log('ğŸ“Š å“åº”çŠ¶æ€:', response.status)

    if (!response.ok) {
      const errorText = await response.text()
      console.error('âŒ APIé”™è¯¯å“åº”:', errorText)
      
      let errorData
      try {
        errorData = JSON.parse(errorText)
      } catch {
        errorData = { error: { message: errorText } }
      }

      let solution = ''
      if (response.status === 401 || response.status === 403) {
        solution = 'è¯·ç¡®ä¿æ‚¨çš„GitHub Personal Access Tokenå…·æœ‰"models:read"æƒé™ã€‚'
      } else if (response.status === 404) {
        solution = 'è¯·æ£€æŸ¥APIç«¯ç‚¹æ˜¯å¦æ­£ç¡®ã€‚'
      }

      return NextResponse.json({
        success: false,
        status: response.status,
        error: errorData,
        solution: solution,
        debug: {
          endpoint: 'https://models.github.ai/inference/chat/completions',
          model: requestBody.model,
          tokenPrefix: githubToken.substring(0, 20) + '...',
          tokenLength: githubToken.length
        }
      })
    }

    const data = await response.json()
    console.log('âœ… GitHub Models APIè°ƒç”¨æˆåŠŸ!')
    
    return NextResponse.json({
      success: true,
      status: response.status,
      message: data.choices?.[0]?.message?.content || 'No content returned',
      debug: {
        endpoint: 'https://models.github.ai/inference/chat/completions',
        model: requestBody.model,
        tokenPrefix: githubToken.substring(0, 20) + '...',
        tokenLength: githubToken.length,
        usage: data.usage
      }
    })

  } catch (error) {
    console.error('âŒ è¯·æ±‚å¤±è´¥:', error)
    
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : String(error),
      solution: 'è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒGitHub Tokené…ç½®',
      debug: {
        endpoint: 'https://models.github.ai/inference/chat/completions',
        tokenPrefix: githubToken.substring(0, 20) + '...',
        tokenLength: githubToken.length
      }
    }, { status: 500 })
  }
}
